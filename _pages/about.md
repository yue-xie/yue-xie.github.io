---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


Welcome to my website! Currently I am a research assistant professor in Musketeers Foundation Institute of Data Science and Department of Mathematics at the University of Hong Kong. Before that, I was a postdoc at Wisconsin Intitute for Discovery and lucky to work with Professor [Stephen J. Wright](http://pages.cs.wisc.edu/~swright/). I received my PhD degree in Pennsylvania State University when I was fortunate to have Professor [Uday V. Shanbhag](https://ioe.engin.umich.edu/people/shanbhag-uday-v/) as my supervisor and thesis advisor. My research interests are continuous, stochastic and robust optimization, with all types of applications including machine learning and data science. You may find more about me in my [CV](https://yue-xie.github.io/files/CV_YX_2026.pdf).

### Outstanding candidates for Phd position with potential for [HKPFS](https://gradsch.hku.hk/prospective_students/fees_scholarships_and_financial_support/hong_kong_phd_fellowship_scheme) are welcome to apply! RA positions are open!

## News

Dec 17, 2025: Our work on A Parameter-Free Stochastic LineseArch Method (SLAM) for Minimizing Expectation Residuals has been submitted and on arXiv ([link](https://arxiv.org/abs/2512.14979)). The algorithm is concise and intuitive - combining sampling with traditional line search scheme to make the stepsize adaptive. The analysis is also intuitive and "simple", and I am surprised that no one seems to discover it before. 

Sep 17, 2025: Our work on Tackling High-Dimensional Nonconvex Stochastic Optimization via Stochastic First-Order Methods with Non-smooth Proximal Terms and Variance Reduction has been on arXiv ([link](https://arxiv.org/abs/2509.13992)). This work includes significant improvement over the previous one ([link](https://arxiv.org/abs/2406.19475)) in many aspects. Behind the improved outcomes are persistent exploration motivated by pursuit of math completeness, and invaluable disucssions with ingenious scholars. I personally like the work and the story behind it very much.

Jun 12, 2025: Our work on Resolution of l1-norm Minimization via Two-metric Adaptive Projection Method has been submitted! Click [here](https://arxiv.org/abs/2504.12260) for the arXiv version.

Sep 29, 2024: Our work on Stochastic First-Order Methods with Non-smooth and Non-Euclidean Proximal Terms for Nonconvex High-Dimensional Stochastic Optimization has been submitted and under 2nd round review of Mathematical Programming! Click [here](https://arxiv.org/abs/2406.19475) for the arXiv version.

May 20, 2024: Our work on Randomized methods for computing optimal transport without regularization and their convergence analysis has been accepted by <i>Journal of Scientific Computing</i> [Link](https://link.springer.com/article/10.1007/s10915-024-02570-w).


